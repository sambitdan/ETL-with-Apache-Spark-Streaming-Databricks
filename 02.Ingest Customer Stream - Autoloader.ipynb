{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6124f609-29a9-4220-bf17-985cbb921c52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Stream Customer Data using Auto Loader from cloud files to Delta Location\n",
    "<ol>\n",
    "<li> Read files from cloud storage using Data Reader API Auto Loader</li>\n",
    "<p><li> Transform dataframe to add following columns</li>\n",
    "              <ul>\n",
    "              <li>file_path</li>\n",
    "              <li>ingestion date:Current timestamp</li>\n",
    "              </ul>\n",
    "</p>\n",
    "<li> Write Transform Data Stream to Delta Lake Table</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "561ad9f6-310a-4488-ba9a-07779b9bd9a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###1.Read files from cloud storage using Data Reader API Autoloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13c31261-7f96-4ee4-bc76-f8072eb5327e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_df=spark.readStream.format('cloudFiles')\\\n",
    "  .option('cloudFiles.format','json')\\\n",
    "  .option('cloudFiles.schemaLocation','abfss://gizmobox@sambitdatabricksstorage.dfs.core.windows.net/landing/customers_autoloader/_schema')\\\n",
    "  .option('cloudFiles.useNotifications','true')\\\n",
    "  .option('cloudFiles.inferColumnTypes','true')\\\n",
    "  .option('cloudFiles.schemaEvolutionMode','addNewColumns')\\\n",
    "  .option('cloudFiles.rescuedDataColumn','rescued_data')\\\n",
    "  .load('/Volumes/gizmobox_stream_cat/landing/customer_autoloader/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72e08e57-a321-4cd2-98c5-0089c90f497a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4742a340-8567-4ba7-8c2d-473a89d79359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###2.Transform dataframe to add following columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecdaad05-c86f-4d56-a6ae-bd4c9bfbe973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab37615-adcc-459a-a0a1-51f38956b771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_transformed_df=customer_df.withColumn('filepath',col('_metadata.file_path'))\\\n",
    "    .withColumn('ingestion_date',current_timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e160261-f8a3-4656-9231-c09752aff32a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###3.Write Transform Data Stream to Delta Lake Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6ca23b3-d0ab-46e6-a4a1-7bd837186345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "streaming_query=customer_transformed_df.writeStream.format('delta')\\\n",
    "  .outputMode('append')\\\n",
    "  .trigger(processingTime=\"2 minutes\")\\\n",
    "  .option('checkpointLocation','/Volumes/gizmobox_stream_cat/landing/customer_stream/_checkpoint_stream').toTable('gizmobox_stream_cat.bronze.customers_stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "762c4b2d-6ded-4c50-a2c8-ad9a71adf4ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "streaming_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "608f532b-86ec-482e-9642-1a1d4b137de0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from gizmobox_stream_cat.bronze.customers_stream;\n",
    "-- this select statement is not running as streaming query but .writeStream is working on streaming query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7f1d42d-0d72-4a33-8b1d-e6f8c3c3ee96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6424793006718050,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02.Ingest Customer Stream - Autoloader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
